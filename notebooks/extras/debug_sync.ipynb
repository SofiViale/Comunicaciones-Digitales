{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce5dd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Changed working directory to project root: /home/fernando/Documents/LoRaPriv\n"
     ]
    }
   ],
   "source": [
    "#------------------- Change working directory to project root -------------------#\n",
    "from pathlib import Path, os\n",
    "\n",
    "cur = Path().resolve()\n",
    "while not (cur / \"src\").is_dir():\n",
    "    if cur == cur.parent: raise RuntimeError(\"No 'src' dir\")\n",
    "    cur = cur.parent\n",
    "\n",
    "os.chdir(cur)\n",
    "print(f\"[INFO] Changed working directory to project root: {cur}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13256e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------- External Libraries --------------------------------------\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Callable\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import time\n",
    "# ----------------------------------------- Local Imports ----------------------------------------\n",
    "from src.core                  import LoRaPhyParams, LoRaFrameParams\n",
    "from src.mod                   import LoRaModulator\n",
    "from src.demod                 import LoRaDemodulator\n",
    "from src.sync                  import DechirpBasedSynchronizer\n",
    "from src.core.vpn_utils        import VPNKeepAlive\n",
    "\n",
    "import src.core.sdr_utils as sdr_utils\n",
    "import src.core.snr_utils as snr_utils\n",
    "import src.core.perf_metrics_utils as perf_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601c9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOD_BACKEND = \"numpy\"  \n",
    "DEMOD_BACKEND = \"cupy\" \n",
    "payload_syms_count = 1000\n",
    "SIMULATIONS_BUFFER_SIZE = 2**20  # Tamaño del buffer para simulaciones\n",
    "\n",
    "class ReceivedSyncError(Exception):\n",
    "    \"\"\"Excepción para errores de sincronización recibidos.\"\"\"\n",
    "    def __init__(self, message):\n",
    "        super().__init__(message)\n",
    "        self.message = message\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"ReceivedSyncError: {self.message}\"\n",
    "\n",
    "def run(snr_db):\n",
    "\n",
    "    profile_name = \"sf7_500k_2spc_0fpa.json\"\n",
    "    profile = snr_utils.SDRProfile.load(f\"lora_sim/{profile_name}\")\n",
    "\n",
    "    modulator=LoRaModulator(profile.phy_params, profile.frame_params, backend=MOD_BACKEND)\n",
    "\n",
    "    synchronizer=DechirpBasedSynchronizer(profile.phy_params, profile.frame_params, backend=DEMOD_BACKEND, fold_mode=profile.fold_mode, max_sync_candidates=50, debug=True, compensate_cfo_sfo=True)\n",
    "\n",
    "    demodulator=LoRaDemodulator(profile.phy_params, backend=DEMOD_BACKEND, fold_mode=profile.fold_mode)\n",
    "\n",
    "    payload = np.random.randint(0, modulator.phy_params.chips_per_symbol, size=payload_syms_count)\n",
    "    modulated_frame = modulator.modulate(payload, include_frame=True)\n",
    "    reference_payload = modulator.modulate(payload, include_frame=False)\n",
    "\n",
    "    # Añade ruido blanco gaussiano al frame modulado\n",
    "    noisy_frame, _, _ = snr_utils.generate_awgn(f\"{snr_db}db\", modulated_frame, reference_payload)\n",
    "\n",
    "    # Repite el frame para que tenga el tamaño de un buffer\n",
    "    buffer_size = SIMULATIONS_BUFFER_SIZE\n",
    "\n",
    "\n",
    "    sync_offset = np.random.randint(0, buffer_size - len(noisy_frame))\n",
    "    #print(f\"[INFO] Sync offset: {sync_offset} samples (or {sync_offset + modulator.phy_params.samples_per_symbol} samples)\")\n",
    "\n",
    "    if len(noisy_frame) < buffer_size:\n",
    "        reps = (buffer_size // len(noisy_frame)) + 1\n",
    "        noisy_frame = np.tile(noisy_frame, reps)\n",
    "\n",
    "    # Desplaza el frame para simular un canal real y un offset aleatorio\n",
    "    received_iq = np.roll(noisy_frame, sync_offset)\n",
    "\n",
    "    #print(f\"[INFO] Other possible frame starts: {np.arange(sync_offset, len(received_iq) - len(modulated_frame), modulated_frame.size)}\")\n",
    "\n",
    "    aligned_payload, traces = synchronizer.run(received_iq)\n",
    "    demodulated_symbols = demodulator.demodulate(aligned_payload)\n",
    "    demodulated_symbols = demodulated_symbols.get() if hasattr(demodulated_symbols, 'get') else demodulated_symbols\n",
    "\n",
    "    if len(demodulated_symbols) != len(payload):\n",
    "        raise ReceivedSyncError(f\"Payload mismatch: {demodulated_symbols} != {payload}\")\n",
    "\n",
    "    # Calcula Errores\n",
    "    ser_err = np.sum(demodulated_symbols != np.asarray(payload))\n",
    "    ber_err = sum(bin(m ^ dm).count('1') for m, dm in zip(payload, demodulated_symbols))\n",
    "    return ser_err, ber_err, traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17805d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sent 1000 frames with SNR -10 dB\n",
      "Successful frames: 817\n",
      "FER: 18.30%\n",
      "SER: 0.031387, BER: 0.015819714285714284\n",
      "No candidates found: 23 times\n",
      "Payload didn't match: 43 times\n",
      "Candidates exhausted: 117 times\n",
      "\n",
      " Why did candidates exhaust? See error summary below:\n",
      "\n",
      "\n",
      "=== Error summary across runs ===\n",
      "Total candidate attempts : 1319\n",
      "Failed candidates       : 502 (38.1%)\n",
      "\n",
      "Most frequent error type: SFDError (368)\n",
      "Top message for 'SFDError': Failed to locate the downchirp pair in SFD. (368)\n",
      "\n",
      "Most failing candidate index: 0 (117)\n"
     ]
    }
   ],
   "source": [
    "from src.sync.dechirp_based_synchronizer import CandidatesExhaustedError, NoCandidatesFoundError\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# ---- Parameters ----\n",
    "snr_db = -10\n",
    "NUM_ITERS = 1000  # adjust as needed\n",
    "no_candidates_found = 0\n",
    "received_sync_errors = 0\n",
    "candidates_exhausted = 0\n",
    "all_traces = []\n",
    "\n",
    "total_ser_err = 0\n",
    "total_ber_err = 0\n",
    "for _ in range(NUM_ITERS):\n",
    "    try:\n",
    "        ser_err, ber_err, traces = run(snr_db)\n",
    "        # Optional: print per-run error metrics\n",
    "        total_ser_err += ser_err\n",
    "        total_ber_err += ber_err\n",
    "    except NoCandidatesFoundError as e:\n",
    "        traces = []\n",
    "        no_candidates_found += 1\n",
    "    except CandidatesExhaustedError as e:\n",
    "        traces = getattr(e, \"traces\", []) or []\n",
    "        candidates_exhausted += 1\n",
    "    except ReceivedSyncError as e:\n",
    "        traces = []\n",
    "        received_sync_errors += 1\n",
    "\n",
    "    all_traces.extend(traces or [])\n",
    "\n",
    "# ---- Summary of most frequent errors across all iterations ----\n",
    "def summarize_errors(traces):\n",
    "    \"\"\"\n",
    "    Build minimal frequency summaries using only fields present in traces:\n",
    "    - error_type\n",
    "    - error_msg\n",
    "    - index (candidate index)\n",
    "    - status (\"success\" | \"error\")\n",
    "    \"\"\"\n",
    "    total = len(traces)\n",
    "    failed = [t for t in traces if getattr(t, \"status\", \"error\") != \"success\"]\n",
    "\n",
    "    by_type = Counter(getattr(t, \"error_type\", \"-\") or \"-\" for t in failed)\n",
    "    by_type_msg = Counter(\n",
    "        ((getattr(t, \"error_type\", \"-\") or \"-\"), (getattr(t, \"error_msg\", \"-\") or \"-\"))\n",
    "        for t in failed\n",
    "    )\n",
    "    by_index = Counter(getattr(t, \"index\", -1) for t in failed)\n",
    "\n",
    "    print(\"\\n=== Error summary across runs ===\")\n",
    "    print(f\"Total candidate attempts : {total}\")\n",
    "    print(f\"Failed candidates       : {len(failed)} ({(100.0*len(failed)/total if total else 0.0):.1f}%)\")\n",
    "\n",
    "    if by_type:\n",
    "        top_type, top_cnt = by_type.most_common(1)[0]\n",
    "        print(f\"\\nMost frequent error type: {top_type} ({top_cnt})\")\n",
    "\n",
    "        # Show the most frequent message for that type\n",
    "        msg_counts = Counter({msg: cnt for (etype, msg), cnt in by_type_msg.items() if etype == top_type})\n",
    "        if msg_counts:\n",
    "            top_msg, top_msg_cnt = msg_counts.most_common(1)[0]\n",
    "            print(f\"Top message for '{top_type}': {top_msg} ({top_msg_cnt})\")\n",
    "\n",
    "    if by_index:\n",
    "        idx, cnt = by_index.most_common(1)[0]\n",
    "        print(f\"\\nMost failing candidate index: {idx} ({cnt})\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nSent {NUM_ITERS} frames with SNR {snr_db} dB\")\n",
    "print(f\"Successful frames: {NUM_ITERS - no_candidates_found - received_sync_errors - candidates_exhausted}\")\n",
    "print(f\"FER: {(received_sync_errors + candidates_exhausted + no_candidates_found) / NUM_ITERS if NUM_ITERS > 0 else 0:.2%}\")\n",
    "print(f\"SER: {total_ser_err/(NUM_ITERS*1000)}, BER: {total_ber_err/(NUM_ITERS*7000)}\")\n",
    "print(f\"No candidates found: {no_candidates_found} times\")\n",
    "print(f\"Payload didn't match: {received_sync_errors} times\")\n",
    "print(f\"Candidates exhausted: {candidates_exhausted} times\")\n",
    "\n",
    "print(f\"\\n Why did candidates exhaust? See error summary below:\\n\")\n",
    "# Run the summary\n",
    "summarize_errors(all_traces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b80c3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sent 1000 frames with SNR -10 dB\n",
      "Successful frames: 913\n",
      "FER: 8.70%\n",
      "SER: 0.084742, BER: 0.030260285714285715\n",
      "No candidates found: 12 times\n",
      "Payload didn't match: 55 times\n",
      "Candidates exhausted: 20 times\n",
      "\n",
      " Why did candidates exhaust? See error summary below:\n",
      "\n",
      "\n",
      "=== Error summary across runs ===\n",
      "Total candidate attempts : 986\n",
      "Failed candidates       : 73 (7.4%)\n",
      "\n",
      "Most frequent error type: IncompletePayloadError (40)\n",
      "Top message for 'IncompletePayloadError': IQ buffer too short to extract as many payload symbols as the header indicates. (40)\n",
      "\n",
      "Most failing candidate index: 0 (24)\n"
     ]
    }
   ],
   "source": [
    "from src.sync.dechirp_based_synchronizer import CandidatesExhaustedError, NoCandidatesFoundError\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# ---- Parameters ----\n",
    "snr_db = -10\n",
    "NUM_ITERS = 1000  # adjust as needed\n",
    "no_candidates_found = 0\n",
    "received_sync_errors = 0\n",
    "candidates_exhausted = 0\n",
    "all_traces = []\n",
    "\n",
    "total_ser_err = 0\n",
    "total_ber_err = 0\n",
    "for _ in range(NUM_ITERS):\n",
    "    try:\n",
    "        ser_err, ber_err, traces = run(snr_db)\n",
    "        # Optional: print per-run error metrics\n",
    "        total_ser_err += ser_err\n",
    "        total_ber_err += ber_err\n",
    "    except NoCandidatesFoundError as e:\n",
    "        traces = []\n",
    "        no_candidates_found += 1\n",
    "    except CandidatesExhaustedError as e:\n",
    "        traces = getattr(e, \"traces\", []) or []\n",
    "        candidates_exhausted += 1\n",
    "    except ReceivedSyncError as e:\n",
    "        traces = []\n",
    "        received_sync_errors += 1\n",
    "\n",
    "    all_traces.extend(traces or [])\n",
    "\n",
    "# ---- Summary of most frequent errors across all iterations ----\n",
    "def summarize_errors(traces):\n",
    "    \"\"\"\n",
    "    Build minimal frequency summaries using only fields present in traces:\n",
    "    - error_type\n",
    "    - error_msg\n",
    "    - index (candidate index)\n",
    "    - status (\"success\" | \"error\")\n",
    "    \"\"\"\n",
    "    total = len(traces)\n",
    "    failed = [t for t in traces if getattr(t, \"status\", \"error\") != \"success\"]\n",
    "\n",
    "    by_type = Counter(getattr(t, \"error_type\", \"-\") or \"-\" for t in failed)\n",
    "    by_type_msg = Counter(\n",
    "        ((getattr(t, \"error_type\", \"-\") or \"-\"), (getattr(t, \"error_msg\", \"-\") or \"-\"))\n",
    "        for t in failed\n",
    "    )\n",
    "    by_index = Counter(getattr(t, \"index\", -1) for t in failed)\n",
    "\n",
    "    print(\"\\n=== Error summary across runs ===\")\n",
    "    print(f\"Total candidate attempts : {total}\")\n",
    "    print(f\"Failed candidates       : {len(failed)} ({(100.0*len(failed)/total if total else 0.0):.1f}%)\")\n",
    "\n",
    "    if by_type:\n",
    "        top_type, top_cnt = by_type.most_common(1)[0]\n",
    "        print(f\"\\nMost frequent error type: {top_type} ({top_cnt})\")\n",
    "\n",
    "        # Show the most frequent message for that type\n",
    "        msg_counts = Counter({msg: cnt for (etype, msg), cnt in by_type_msg.items() if etype == top_type})\n",
    "        if msg_counts:\n",
    "            top_msg, top_msg_cnt = msg_counts.most_common(1)[0]\n",
    "            print(f\"Top message for '{top_type}': {top_msg} ({top_msg_cnt})\")\n",
    "\n",
    "    if by_index:\n",
    "        idx, cnt = by_index.most_common(1)[0]\n",
    "        print(f\"\\nMost failing candidate index: {idx} ({cnt})\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nSent {NUM_ITERS} frames with SNR {snr_db} dB\")\n",
    "print(f\"Successful frames: {NUM_ITERS - no_candidates_found - received_sync_errors - candidates_exhausted}\")\n",
    "print(f\"FER: {(received_sync_errors + candidates_exhausted + no_candidates_found) / NUM_ITERS if NUM_ITERS > 0 else 0:.2%}\")\n",
    "print(f\"SER: {total_ser_err/(NUM_ITERS*1000)}, BER: {(total_ber_err)/(NUM_ITERS*7000)}\")\n",
    "print(f\"No candidates found: {no_candidates_found} times\")\n",
    "print(f\"Payload didn't match: {received_sync_errors} times\")\n",
    "print(f\"Candidates exhausted: {candidates_exhausted} times\")\n",
    "\n",
    "print(f\"\\n Why did candidates exhaust? See error summary below:\\n\")\n",
    "# Run the summary\n",
    "summarize_errors(all_traces)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
